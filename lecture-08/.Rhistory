Classifiers are a type of supervised learning problem that handles target features that contain dis
- Clustering of records focuses on finding groups of records that are statistically similar
- Dimensionality reduction focuses on finding groups of variables that
#Section 2 - Methods
[]
## K-Means
Technique for finding natural groups
Uses
- customer or persona segmentation, often used for strategic plans and operating plans
- identifying hotspots
- finding natural breaks in data for colour coding
```
Let k > 1, R is the feature space.
Normalize all input features into same range.
Drop or impute all missing values NA
Select a value of k
Initialize by randomly select k centroids in feature space R
Calculate distance from each record to each of the k centroids
While each point's assignment changes:
Assignment Step: Assign each point to the nearest centroid
Update Step: Re-calculate centroid for each group of points
Stop when assignments no longer change
```
### Considerations
- _Stability of Clusters_. A common error is to assume that the groups are stable
- _Missing Values_. K-Means do not handle missing values well as each data point is essentially a coordinate. Thus, often times K-Means are calibrated on complete data sets.
- _Normalization_. All features need to be standardized. Binary or discrete features do not perform well.
- _Stability_. Stability of clusters must be tested
### K-Means and World Development Indiactors
## Agglomerative Clustering
asd
## Principal Components
asd
d <- dist(as.matrix(data))   # find distance matrix
hc <- hclust(d)                # apply hirarchical clustering
plot(hc)                       # plot the dendrogram
library("flexclust")
set.seed(123)
data <- data.frame(x = rnorm(10,20,10),
y = rnorm(10,20,10))
data2 <- data.frame(x = rnorm(5,0,5),
y = rnorm(5,30,5))
data3 <- data.frame(x = rnorm(20,-10,5),
y = rnorm(20,-10,5))
data4 <- data.frame(x = rnorm(3,20,5),
y = rnorm(3,-30,5))
data <- rbind(data, data2, data3, data4)
d <- dist(as.matrix(data))   # find distance matrix
hc <- hclust(d)                # apply hirarchical clustering
plot(hc)                       # plot the dendrogram
library("flexclust")
set.seed(123)
data <- data.frame(x = rnorm(10,20,10),
y = rnorm(10,20,10),
z = paste0("a",1:10))
data2 <- data.frame(x = rnorm(5,0,5),
y = rnorm(5,30,5),
z = paste0("b",1:5))
data3 <- data.frame(x = rnorm(20,-10,5),
y = rnorm(20,-10,5),
z = paste0("c",1:20))
data4 <- data.frame(x = rnorm(3,20,5),
y = rnorm(3,-30,5),
z = paste0("d",1:3))
data <- rbind(data, data2, data3, data4)
d <- dist(as.matrix(data))   # find distance matrix
hc <- hclust(d)                # apply hirarchical clustering
plot(hc)                       # plot the dendrogram
row.names(data) <- data$z
d <- dist(as.matrix(data))   # find distance matrix
hc <- hclust(d)                # apply hirarchical clustering
plot(hc)                       # plot the dendrogram
library("flexclust")
set.seed(123)
data <- data.frame(x = rnorm(10,20,10),
y = rnorm(10,20,10),
z = paste0("a",1:10))
data2 <- data.frame(x = rnorm(5,0,5),
y = rnorm(5,30,5),
z = paste0("b",1:5))
data3 <- data.frame(x = rnorm(20,-10,5),
y = rnorm(20,-10,5),
z = paste0("c",1:20))
data4 <- data.frame(x = rnorm(3,20,5),
y = rnorm(3,-30,5),
z = paste0("d",1:3))
data <- rbind(data, data2, data3, data4)
row.names(data) <- data$z
d <- dist(as.matrix(data))
hc <- hclust(d)
plot(hc, main = "Hierarchical Clustering Example")
#Example data
setwd("/Users/jeff/Documents/Github/data-science/lecture-09/data")
data <- read.csv("WDI-2016.csv")
dropregions <- c('ARB', 'CEB', 'CSS', 'EAP', 'EAR', 'EAS', 'UMC','ECA', 'ECS','SAS', 'EMU','EUU', 'FCS', 'HIC', 'HPC', 'IBD', 'IBT', 'IDA','INX', 'IDB', 'IDX', 'LAC', 'LCN', 'LDC', 'LIC', 'LMC', 'LMY', 'LTE', 'MEA', 'MIC', 'MNA', 'NAC', 'OED', 'OSS', 'PRE', 'PSS', 'PST', 'SSA', 'SSF', 'SST', 'TEA', 'TEC', 'TLA', 'TMN', 'TSA', 'TSS', 'WLD')
data2 <- data[!(data$Country.Code %in% dropregions), ]
data2 <- data2[, c(1,2,3,4,55)]
#Create indicators list
indicators <- data2[!duplicated(data2[,c(3:4)]),c(3,4)]
#Create wide data
data2 <- data2[, c(2,4,5)]
data3 <- reshape(data2, direction = "wide",
idvar = "Country.Code",
timevar = "Indicator.Code")
#Drop
data4 <- data3
tablist <- data.frame()
for(k in ncol(data4):2){
tablist <- rbind(tablist,
data.frame(var = k,
count = sum(is.na(data4[,k]))/nrow(data4)))
}
#KNN Example
keeplist <- tablist[tablist$count < 0.1, 1]
data4 <- data4[,c(1,keeplist)]
#
#stand
stand.vec <- function(vec, options = 1){
if(options == 1){
#mean-center, sd standard
vec <- (vec - mean(vec, na.rm = T))/sd(vec, na.rm = T)
} else if(options == 2){
#range standardization
vec <- (vec - min(vec, na.rm = T))/(max(vec, na.rm = T) - min(vec, na.rm = T))
}
return(vec)
}
for(k in 2:ncol(data4)){
data4[,k] <- stand.vec(data4[,k], 1)
}
#Either omit or impute
data4 <- na.omit(data4)
#library(VIM)
data4 <- kNN(data4, k=3)
dim(data4)
master <- data.frame()
for(i in 1:182){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = cl$betweenss/cl$totss))
}
cl
cl$betweenss
for(i in 1:182){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = cl$withinss))
}
#Example data
setwd("/Users/jeff/Documents/Github/data-science/lecture-09/data")
data <- read.csv("WDI-2016.csv")
dropregions <- c('ARB', 'CEB', 'CSS', 'EAP', 'EAR', 'EAS', 'UMC','ECA', 'ECS','SAS', 'EMU','EUU', 'FCS', 'HIC', 'HPC', 'IBD', 'IBT', 'IDA','INX', 'IDB', 'IDX', 'LAC', 'LCN', 'LDC', 'LIC', 'LMC', 'LMY', 'LTE', 'MEA', 'MIC', 'MNA', 'NAC', 'OED', 'OSS', 'PRE', 'PSS', 'PST', 'SSA', 'SSF', 'SST', 'TEA', 'TEC', 'TLA', 'TMN', 'TSA', 'TSS', 'WLD')
data2 <- data[!(data$Country.Code %in% dropregions), ]
data2 <- data2[, c(1,2,3,4,55)]
#Create indicators list
indicators <- data2[!duplicated(data2[,c(3:4)]),c(3,4)]
#Create wide data
data2 <- data2[, c(2,4,5)]
data3 <- reshape(data2, direction = "wide",
idvar = "Country.Code",
timevar = "Indicator.Code")
#Drop
data4 <- data3
tablist <- data.frame()
for(k in ncol(data4):2){
tablist <- rbind(tablist,
data.frame(var = k,
count = sum(is.na(data4[,k]))/nrow(data4)))
}
#KNN Example
keeplist <- tablist[tablist$count < 0.1, 1]
data4 <- data4[,c(1,keeplist)]
#
#stand
stand.vec <- function(vec, options = 1){
if(options == 1){
#mean-center, sd standard
vec <- (vec - mean(vec, na.rm = T))/sd(vec, na.rm = T)
} else if(options == 2){
#range standardization
vec <- (vec - min(vec, na.rm = T))/(max(vec, na.rm = T) - min(vec, na.rm = T))
}
return(vec)
}
for(k in 2:ncol(data4)){
data4[,k] <- stand.vec(data4[,k], 1)
}
#Either omit or impute
#data4 <- na.omit(data4)
#library(VIM)
data4 <- kNN(data4, k=3)
dim(data4)
master <- data.frame()
for(i in 1:182){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = cl$withinss))
}
plot(master)
cl$withinss
sum(cl$withinss)
master <- data.frame()
for(i in 1:182){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = sum(cl$withinss)))
}
plot(master)
for(i in 1:50){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = sum(cl$withinss)))
}
plot(master)
master <- data.frame()
for(i in 1:50){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = sum(cl$withinss)))
}
plot(master)
plot(master, type = "l")
cl <- kmeans(data4[,2:ncol(data4)], centers = 3)
table(cl$cluster)
data4 <- data3
tablist <- data.frame()
for(k in ncol(data4):2){
tablist <- rbind(tablist,
data.frame(var = k,
count = sum(is.na(data4[,k]))/nrow(data4)))
}
#KNN Example
keeplist <- tablist[tablist$count < 0.1, 1]
data4 <- data4[,c(1,keeplist)]
#
#stand
stand.vec <- function(vec, options = 1){
if(options == 1){
#mean-center, sd standard
vec <- (vec - mean(vec, na.rm = T))/sd(vec, na.rm = T)
} else if(options == 2){
#range standardization
vec <- (vec - min(vec, na.rm = T))/(max(vec, na.rm = T) - min(vec, na.rm = T))
}
return(vec)
}
for(k in 2:ncol(data4)){
data4[,k] <- stand.vec(data4[,k], 1)
}
#Either omit or impute
data4 <- na.omit(data4)
#library(VIM)
data4 <- kNN(data4, k=3)
#
dim(data4)
master <- data.frame()
for(i in 1:50){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = sum(cl$withinss)))
}
plot(master, type = "l")
cl <- kmeans(data4[,2:ncol(data4)], centers = 3)
table(cl$cluster)
42/(42+104+4)
65/(65+148+4)
data4$lab <- cl$cluster
View(data4)
View(data4[,c(1,ncol(data4))])
for(i in 1:30){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = sum(cl$withinss)))
}
plot(master, type = "l")
cl <- kmeans(data4[,2:ncol(data4)], centers = 3)
master <- data.frame()
for(i in 1:30){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = sum(cl$withinss)))
}
plot(master, type = "l")
cl <- kmeans(data4[,2:ncol(data4)], centers = 3)
plot(master)
cl <- kmeans(data4[,2:ncol(data4)], centers = 5)
data4$lab <- cl$cluster
View(data4[,c(1,ncol(data4))])
master <- data.frame()
for(i in 1:30){
cl <- kmeans(data4[,2:ncol(data4)], centers = i)
master <- rbind(master,data.frame(k = i, totss = sum(cl$withinss)))
}
plot(master)
cl <- kmeans(data4[,2:ncol(data4)], centers = 8)
data4$lab <- cl$cluster
View(data4[,c(1,ncol(data4))])
load("~/Google Drive/Georgetown/homework2/homework/scoring/hmwk2_scored.Rda")
########################
## Homework #2 SCORING##
########################
dir <- "/Users/jeff/Google Drive/Georgetown/homework2/homework/scoring/"
#Answer key
load(paste0(dir,"hmwk2_key.Rda"))
hmwk.df$answer <- hmwk.df$emp
hmwk.df$pred.flag <- hmwk.df$year==2016
hmwk.master <- hmwk.df[,c("GEOID","date","answer","pred.flag")]
#get student code
scripts <- list.files(paste0(dir,"students"))
#load MAPE
mape <- function(yhat, y){
return(100*mean(abs(yhat/y - 1), na.rm=T))
}
#Set up dummy
scoresheet <- data.frame()
city.choice <- c()
score.pred <-data.frame()
for(s in 1:length(scripts)){
starttime <- as.numeric(proc.time()[3])
print(s)
source(paste0(dir,"students/",scripts[s]))
duration <- as.numeric(proc.time()[3])- starttime
n480 <- nrow(myPredictions)
myPredictions$GEOID <- as.character(myPredictions$GEOID )
predictions <- merge(myPredictions, hmwk.master, by = c("GEOID","date"))
predictions <- predictions[predictions$pred.flag==TRUE, ]
outpred <- data.frame(predictions, id = scripts[s])
score.pred <- rbind(score.pred,outpred)
mape.score <- mape(predictions$yhat, predictions$answer)
mape.score
if(mape.score < 2.5){
hmwk.score <- 8
} else  if(mape.score < 3){
hmwk.score <- 7
} else  if(mape.score < 4){
hmwk.score <- 6
} else {
hmwk.score <- 5
}
scoresheet <- rbind(scoresheet,
data.frame(script = scripts[s],
mape = mape.score,
hmwk.score = hmwk.score,
n480 = n480 == 480,
time = duration
))
city.choice <- c(city.choice, unique(as.numeric(as.character(predictions$GEOID))))
rm(myPrediction, predictions, mape.score)
}
save(scoresheet, city.choice, score.pred, file = paste0(dir,"hmwk2_scored.Rda"))
write.csv(scoresheet, paste0(dir,"scoresheet.csv"), row.names=FALSE)
View(results)
table(results$GEOID)
table(results$GEOID)/480
View(results)
table(city.choice)
View(hmwk.master)
s=11
starttime <- as.numeric(proc.time()[3])
print(s)
source(paste0(dir,"students/",scripts[s]))
duration <- as.numeric(proc.time()[3])- starttime
n480 <- nrow(myPredictions)
myPredictions$GEOID <- as.character(myPredictions$GEOID )
predictions <- merge(myPredictions, hmwk.master, by = c("GEOID","date"))
predictions <- predictions[predictions$pred.flag==TRUE, ]
for(k in unique(predictions$GEOID)){
print(paste(k,": ", mape(predictions[predictions$GEOID==k,"yhat"], predictions[predictions$GEOID==k,"answer"])))
}
for(k in unique(predictions$GEOID)){
predictions2 <- predictions[predictions$pred.flag==TRUE, ]
print(paste(k,": ", mape(predictions[predictions2$GEOID==k,"yhat"], predictions[predictions2$GEOID==k,"answer"])))
}
myPredictions$GEOID <- as.character(myPredictions$GEOID )
predictions <- merge(myPredictions, hmwk.master, by = c("GEOID","date"))
predictions <- predictions[predictions$pred.flag==TRUE, ]
mape.score <- mape(predictions$yhat, predictions$answer)
mape.score
scripts[s]
myPredictions$GEOID <- as.character(myPredictions$GEOID )
predictions <- merge(myPredictions, hmwk.master, by = c("GEOID","date"))
predictions <- predictions[predictions$pred.flag==TRUE, ]
mape.score <- mape(predictions$yhat, predictions$answer)
mape.score
View(scoresheet)
########################
## Homework #2 SCORING##
########################
dir <- "/Users/jeff/Google Drive/Georgetown/homework2/homework/scoring/"
#Answer key
load(paste0(dir,"hmwk2_key.Rda"))
hmwk.df$answer <- hmwk.df$emp
hmwk.df$pred.flag <- hmwk.df$year==2016
hmwk.master <- hmwk.df[,c("GEOID","date","answer","pred.flag")]
#get student code
scripts <- list.files(paste0(dir,"students"))
#load MAPE
mape.func <- function(yhat, y){
return(100*mean(abs(yhat/y - 1), na.rm=T))
}
#Set up dummy
scoresheet <- data.frame()
city.choice <- c()
score.pred <-data.frame()
for(s in 1:length(scripts)){
starttime <- as.numeric(proc.time()[3])
print(s)
source(paste0(dir,"students/",scripts[s]))
duration <- as.numeric(proc.time()[3])- starttime
n480 <- nrow(myPredictions)
myPredictions$GEOID <- as.character(myPredictions$GEOID )
predictions <- merge(myPredictions, hmwk.master, by = c("GEOID","date"))
predictions <- predictions[predictions$pred.flag==TRUE, ]
outpred <- data.frame(predictions, id = scripts[s])
score.pred <- rbind(score.pred,outpred)
mape.score <- mape.func(predictions$yhat, predictions$answer)
mape.score
if(mape.score < 2.5){
hmwk.score <- 8
} else  if(mape.score < 3){
hmwk.score <- 7
} else  if(mape.score < 4){
hmwk.score <- 6
} else {
hmwk.score <- 5
}
scoresheet <- rbind(scoresheet,
data.frame(script = scripts[s],
mape = mape.score,
hmwk.score = hmwk.score,
n480 = n480 == 480,
time = duration
))
city.choice <- c(city.choice, unique(as.numeric(as.character(predictions$GEOID))))
rm(myPrediction, predictions, mape.score)
}
save(scoresheet, city.choice, score.pred, file = paste0(dir,"hmwk2_scored.Rda"))
write.csv(scoresheet, paste0(dir,"scoresheet.csv"), row.names=FALSE)
install.packages(c("e1071" ))
install.packages(c("e1071"))
setwd("/Users/jeff/Documents/Github/data-science/lecture-08")
#Load data
health <- read.csv("data/lecture7.csv")
str(health)
#Randomly subset data into train and test
set.seed(100)
rand <- runif(nrow(health))
rand <- rand > 0.5
#Create train test sets
train <- health[rand == T, ]
test <- health[rand == F, ]
health <- read.csv("data/lecture8.csv")
str(health)
#Randomly subset data into train and test
set.seed(100)
rand <- runif(nrow(health))
rand <- rand > 0.5
#Create train test sets
train <- health[rand == T, ]
test <- health[rand == F, ]
glm.fit <- glm(coverage ~ ., data = train, family = binomial())
summary(glm.fit)
exp(glm.fit$coefficients)
pred.glm.train <- predict(glm.fit, train, type = "response")
pred.glm.test <- predict(glm.fit, test, type = "response")
summary(pred.glm.train)
#plotROC
library(plotROC)
library(ggplot2)
#Set up ROC inputs
input.glm <- rbind(data.frame(model = "train", d = train$coverage, m = pred.glm.train),
data.frame(model = "test", d = test$coverage,  m = pred.glm.test))
#Graph all three ROCs
roc.glm <- ggplot(input.glm, aes(d = d, model = model, m = m, colour = model)) +
geom_roc(show.legend = TRUE) + style_roc()  + ggtitle("ROC: GLM")
#AUC
calc_auc(roc.glm)[,2:3]
library(e1071)
#TRAIN MODEL
#Fit SVM  under default assumptions -- cost = 1, gamma = 0.055
svm.rbf.fit <- svm(coverage ~ ., data=train, kernel = "radial", cost = 1, gamma = 0.05555)
#Tools to review output
printcp(svm.rbf.fit)
#F1 score
meanf1 <- function(actual, predicted){
#Mean F1 score function
#actual = a vector of actual labels
#predicted = predicted labels
classes <- unique(actual)
results <- data.frame()
for(k in classes){
results <- rbind(results,
data.frame(class.name = k,
weight = sum(actual == k)/length(actual),
precision = sum(predicted == k & actual == k)/sum(predicted == k),
recall = sum(predicted == k & actual == k)/sum(actual == k)))
}
results$score <- results$weight * 2 * (results$precision * results$recall) / (results$precision + results$recall)
return(sum(results$score))
}
#Prep grid search
cost.vec <- 10^(-1:2)
gamma.vec <- 2^(seq(-5,2,2))
combo <- expand.grid(cost = cost.vec, gamma = gamma.vec)
combo$f1 <- NA
#Search
for(i in 1:nrow(combo)){
fit <- svm(coverage ~ ., data=train, kernel = "radial", cost = combo[i, 1], gamma = combo[i, 2])
pred <- predict(fit, train)
combo$f1[i] <- meanf1(train$coverage, pred)
}
#View table
print(combo)
#Predict labels
pred.test <- svm(coverage ~ ., data = train, kernel = "radial", cost = 1, gamma = 8)
pred.rbf <- predict(pred.test, test)
#examine result
table(pred.rbf)
##RBF
meanf1(test$coverage, pred.rbf)
library(e1071)
