episodes <- rbind(episodes,out)
if(k %% 10 == 0){
save(episodes, transcripts, file = "TAL1to641.Rda")
}
}
#####################################
##Custom code to download TAL files##
#####################################
#Set directory
dir <- "/Users/jeff/Documents/Github/getThisAmericanLife/data"
max.ep <- 641
#Load getTAL(), requires rvest
source("https://raw.githubusercontent.com/SigmaMonstR/getThisAmericanLife/master/script/getTAL.R")
#Set up tables
setwd(dir)
episodes <- data.frame()
#Loop through each episode
for(k in 1:max.ep){
print(k)
Sys.sleep(runif(1)*2)
out <- getTAL(k)
episodes <- rbind(episodes,out)
if(k %% 10 == 0){
save(episodes, transcripts, file = "TAL1to641.Rda")
}
}
#
save(episodes, file = "TAL1to641.Rda")
write.csv(episodes, "TAL_episodes.csv", row.names = FALSE)
for(k in 241:max.ep){
print(k)
Sys.sleep(runif(1)*2)
out <- getTAL(k)
episodes <- rbind(episodes,out)
if(k %% 10 == 0){
save(episodes, transcripts, file = "TAL1to641.Rda")
}
}
save(episodes, file = "TAL1to641.Rda")
########################################
##getTAL. Download episode transcripts##
########################################
getTAL <- function(ep_num){
# A function to download episode transcripts from ThisAmericanLife.org
#
# Args:
#       ep_num: an integer corresponding to an episode number
#
# Returns:
#       A list containing one data frame
#
require(rvest)
url <- paste0("https://www.thisamericanlife.org/", ep_num, "/transcript")
tal <- read_html(url)
title <- tal %>%
html_node("title") %>%
html_text()
#Get all sections
sections <- tal %>%
html_nodes("div.content > div.act")
#Get section heading
dialogue <- data.frame()
if(length(sections) > 0){
for(i in 1:length(sections)){
#Top line
act_title <- html_nodes(sections[[i]], "h3") %>% html_text()
act_num <- i
#Inner
a <- html_nodes(sections[[i]], "div.act-inner > div ")
for(j in 1:length(a)){
print(j)
b <- a[j]
for(m in 1:length(b)){
speaker <- html_nodes(b[m], "h4") %>% html_text()
speaker.type <- html_attr(b[m],"class")
if(length(speaker) == 0){
speaker <- ""
}
line <- html_nodes(b[m], "p") %>% html_text()
times <- html_nodes(b[m], "p") %>% html_attr("begin")
para <- 1:length(times)
dialogue <- rbind(dialogue,
data.frame(ep_num = ep_num,
title = title,
act_title = act_title,
act_num = act_num,
speaker = speaker,
speaker_type = speaker.type,
turn = j,
paragraph = para,
times = times,
text = line))
}
}
}
return(dialogue)
}
}
for(k in 286:max.ep){
print(k)
Sys.sleep(runif(1)*2)
out <- getTAL(k)
episodes <- rbind(episodes,out)
if(k %% 10 == 0){
save(episodes, file = "TAL1to641.Rda")
}
}
#
save(episodes, file = "TAL1to641.Rda")
write.csv(episodes, "TAL_episodes.csv", row.names = FALSE)
ep_num = 314
url <- paste0("https://www.thisamericanlife.org/", ep_num, "/transcript")
tal <- read_html(url)
title <- tal %>%
html_node("title") %>%
html_text()
sections <- tal %>%
html_nodes("div.content > div.act")
#Get section heading
dialogue <- data.frame()
for(i in 1:length(sections)){
#Top line
act_title <- html_nodes(sections[[i]], "h3") %>% html_text()
act_num <- i
#Inner
a <- html_nodes(sections[[i]], "div.act-inner > div ")
for(j in 1:length(a)){
print(j)
b <- a[j]
for(m in 1:length(b)){
speaker <- html_nodes(b[m], "h4") %>% html_text()
speaker.type <- html_attr(b[m],"class")
if(length(speaker) == 0){
speaker <- ""
}
line <- html_nodes(b[m], "p") %>% html_text()
times <- html_nodes(b[m], "p") %>% html_attr("begin")
para <- 1:length(times)
dialogue <- rbind(dialogue,
data.frame(ep_num = ep_num,
title = title,
act_title = act_title,
act_num = act_num,
speaker = speaker,
speaker_type = speaker.type,
turn = j,
paragraph = para,
times = times,
text = line))
}
}
}
title
act_title
act_num
speaker
speaker.type
para
times
line
times
html_nodes(b[m], "p") %>% html_text()
b[m]
html_nodes(b[m], "h4") %>% html_text()
length(speaker)
for(m in 1:length(b)){
speaker <- html_nodes(b[m], "h4") %>% html_text()
speaker.type <- html_attr(b[m],"class")
if(length(speaker) <=1){
speaker <- ""
}
if(length(speaker) <=1){
speaker <- ""
}
line <- html_nodes(b[m], "p") %>% html_text()
times <- html_nodes(b[m], "p") %>% html_attr("begin")
para <- 1:length(times)
dialogue <- rbind(dialogue,
data.frame(ep_num = ep_num,
title = title,
act_title = act_title,
act_num = act_num,
speaker = speaker,
speaker_type = speaker.type,
turn = j,
paragraph = para,
times = times,
text = line))
para
line
line <- html_nodes(b[m], "p") %>% html_text()
line
########################################
##getTAL. Download episode transcripts##
########################################
getTAL <- function(ep_num){
# A function to download episode transcripts from ThisAmericanLife.org
#
# Args:
#       ep_num: an integer corresponding to an episode number
#
# Returns:
#       A list containing one data frame
#
require(rvest)
url <- paste0("https://www.thisamericanlife.org/", ep_num, "/transcript")
tal <- read_html(url)
title <- tal %>%
html_node("title") %>%
html_text()
#Get all sections
sections <- tal %>%
html_nodes("div.content > div.act")
#Get section heading
dialogue <- data.frame()
if(length(sections) > 0){
for(i in 1:length(sections)){
#Top line
act_title <- html_nodes(sections[[i]], "h3") %>% html_text()
act_num <- i
#Inner
a <- html_nodes(sections[[i]], "div.act-inner > div ")
for(j in 1:length(a)){
print(j)
b <- a[j]
for(m in 1:length(b)){
speaker <- html_nodes(b[m], "h4") %>% html_text()
speaker.type <- html_attr(b[m],"class")
if(length(speaker) <=1){
speaker <- ""
}
line <- html_nodes(b[m], "p") %>% html_text()
times <- html_nodes(b[m], "p") %>% html_attr("begin")
para <- 1:length(times)
if(length(line) >=1 && length(times) >= 1){
dialogue <- rbind(dialogue,
data.frame(ep_num = ep_num,
title = title,
act_title = act_title,
act_num = act_num,
speaker = speaker,
speaker_type = speaker.type,
turn = j,
paragraph = para,
times = times,
text = line))
}
}
}
}
return(dialogue)
}
}
for(k in 314:max.ep){
print(k)
Sys.sleep(runif(1)*2)
out <- getTAL(k)
episodes <- rbind(episodes,out)
if(k %% 10 == 0){
save(episodes, file = "TAL1to641.Rda")
}
}
#
save(episodes, file = "TAL1to641.Rda")
write.csv(episodes, "TAL_episodes.csv", row.names = FALSE)
require(RCurl)
########################################
##getTAL: Download episode transcripts##
########################################
getTAL <- function(ep_num){
# A function to download episode transcripts from ThisAmericanLife.org
#
# Args:
#       ep_num: an integer corresponding to an episode number
#
# Returns:
#      A dataframe containing each episode's transcript
#
require(rvest)
require(RCurl)
url <- paste0("https://www.thisamericanlife.org/", ep_num, "/transcript")
if(url.exists(url)){
tal <- read_html(url)
#Get Title
title <- tal %>%
html_node("title") %>%
html_text()
#Get all sections
sections <- tal %>%
html_nodes("div.content > div.act")
#Get section heading
dialogue <- data.frame()
if(length(sections) > 0){
for(i in 1:length(sections)){
#Top line
act_title <- html_nodes(sections[[i]], "h3") %>% html_text()
act_num <- i
#Inner Content
a <- html_nodes(sections[[i]], "div.act-inner > div ")
#Loop through each speaking turn
for(j in 1:length(a)){
print(j)
b <- a[j]
#Within each speaking turn
for(m in 1:length(b)){
#Identify the speaker
speaker <- html_nodes(b[m], "h4") %>% html_text()
#The type of speaker
speaker.type <- html_attr(b[m],"class")
if(length(speaker) <=1){
speaker <- ""
}
#Extract what they said and the timing
line <- html_nodes(b[m], "p") %>% html_text()
times <- html_nodes(b[m], "p") %>% html_attr("begin")
para <- 1:length(times)
#Log the speaker turn, parapgraph, text, etc.
if(length(line) >=1 && length(times) >= 1){
dialogue <- rbind(dialogue,
data.frame(ep_num = ep_num,
title = title,
act_title = act_title,
act_num = act_num,
speaker = speaker,
speaker_type = speaker.type,
turn = j,
paragraph = para,
times = times,
text = line))
}
}
}
}
return(dialogue)
}
}
}
for(k in 460:max.ep){
print(k)
Sys.sleep(runif(1)*2)
out <- getTAL(k)
episodes <- rbind(episodes,out)
if(k %% 10 == 0){
save(episodes, file = "TAL1to641.Rda")
}
}
#
save(episodes, file = "TAL1to641.Rda")
write.csv(episodes, "TAL_episodes.csv", row.names = FALSE)
for(k in 460:max.ep){
print(k)
Sys.sleep(runif(1)*2)
out <- getTAL(k)
episodes <- rbind(episodes,out)
if(k %% 10 == 0){
save(episodes, file = "TAL1to641.Rda")
}
}
for(k in 640:max.ep){
print(k)
Sys.sleep(runif(1)*2)
out <- getTAL(k)
episodes <- rbind(episodes,out)
if(k %% 10 == 0){
save(episodes, file = "TAL1to641.Rda")
}
}
#
episodes <- episodes[!duplicated(episodes),]
save(episodes, file = "TAL1to641.Rda")
write.csv(episodes, "TAL_episodes.csv", row.names = FALSE)
length(unique(episodes$ep_num))
#Set directory
setwd("/Users/jeff/Documents/Github/data-science/lecture-09/data")
#Load in pre-processed data
load("nyc311.Rda")
#Set directory
setwd("/Users/jeff/Documents/Github/data-science/lecture-09/data")
#Load in pre-processed data
load("nyc311.Rda")
#Check what's in the data
dim(nyc311)
colnames(nyc311)
summary(nyc311)
#Custom Function to summarize
sumUp <- function(data, clusters, depth = 3, horizontal = FALSE){
# Summarize cluster variables by most frequent
#
# Args:
#       data: input data
#       clusters: vector of cluster labels
#       depth: top 3 most frequent variables
#       horizontal: control format of results. FALSE means one cluster per row.
#
# Returns:
#       A data frame of k-number of centroids
#
#Calculate means, rotate such that features = rows
overview <- aggregate(data, list(clusters), mean)
overview <- as.data.frame(cbind(colnames(overview)[2:ncol(overview)],
t(overview[,2:ncol(overview)])))
row.names(overview) <- 1:nrow(overview)
overview[,1] <- gsub("count.","",as.character(overview[,1]))
#Clean up values as numerics
for(i in 2:ncol(overview)){
overview[,i] <- round(as.numeric(as.character(overview[,i])),2)
}
#Get top X features
depth.temp <- data.frame()
for(i in 2:ncol(overview)){
temp <- overview[order(-overview[,i]), ]
temp <- paste("(",temp[,i], "): ", temp[,1], sep = "")
temp <- as.data.frame(matrix(temp[1:depth],
nrow = 1,
ncol = depth))
colnames(temp) <- paste0("Rank.", 1:depth)
depth.temp <- rbind(depth.temp, temp)
}
depth.temp <- cbind(data.frame(table(clusters)), depth.temp)
#Rotate?
if(horizontal == TRUE){
depth.temp <- t(depth.temp)
}
return(depth.temp)
}
#What are the 10 most common 311 complaints?
clusters <- rep(1, nrow(nyc311))
sumUp(nyc311[,3:ncol(nyc311)], clusters, 10, horizontal = TRUE)
#Scale data to meet K-Means requirements
nyc311.2 <- scale(nyc311[,c(3:ncol(nyc311))], scale = TRUE, center = TRUE)
i = 3
new <- kmeans(nyc311.2, i)
new$cluster
table(new$cluster)
new$centers
for(i in seq(3,50,3)){
print(i)
new <- kmeans(nyc311.2, i)
master <- rbind(master,
data.frame(k = i,
ss = new$betweenss))
}
master <- data.frame()
for(i in seq(3,50,3)){
print(i)
new <- kmeans(nyc311.2, i)
master <- rbind(master,
data.frame(k = i,
ss = new$betweenss))
}
master
plot(master)
cluster <- kmeans(nyc311.2, 10)$cluster
#Graph results
#Set color palette
palette(colorRampPalette(c('#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a'))(10))
op <- par(mar = rep(0, 4))
plot(nyc311$lon, nyc311$lat, col = factor(cluster), pch = 15, cex = 0.16,
frame.plot=FALSE, yaxt='n', ann=FALSE, xaxt='n')
legend(x="topleft", bty = "n", legend=levels(factor(cluster)),
cex = 1,  x.intersp=0, xjust=0, yjust=0, text.col=seq_along(levels(factor(cluster))))
par(op)
#Results
recap <- sumUp(nyc311[,3:ncol(nyc311)], cluster, 5)
recap
#Results
recap <- sumUp(nyc311[,3:ncol(nyc311)], cluster, 5, horizontal = TRUE)
recape
recap
nyc311.short <- nyc311[sample(1:nrow(nyc311), replace = FALSE, 10000), ]
nyc.short <- scale(nyc311.short[,3:ncol(nyc311.short)])
d <- dist(as.matrix(nyc.short), method = "euclidean")
hc <- hclust(d, method="ward.D")
hc1 <- hclust(d, method="single")
plot(hc, main = "Hierarchical Clustering Example", cex = 0.001)
rect.hclust(hc, k = 10, border="red")
# draw dendogram with red borders around the X clusters
plot(hc1, cex = 0.001)
#Label groups
groups <- cutree(hc, k=10) # cut tree into 5 clusters
table(groups)
palette(colorRampPalette(c('#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a'))(10))
#Graph lat-lons with color coding by cluster
op <- par(mar = rep(0, 4))
plot(nyc311.short$lon, nyc311.short$lat, col = factor(groups), pch = 15, cex = 0.2,
frame.plot=FALSE, yaxt='n', ann=FALSE, xaxt='n')
legend(x="topleft", bty = "n", legend=levels(factor(groups)),
cex = 1,  x.intersp=0, xjust=0, yjust=0, text.col=seq_along(levels(factor(groups))))
par(op)
set.seed(120)
nyc311.short <- nyc311[sample(1:nrow(nyc311), replace = FALSE, 10000), ]
nyc.short <- scale(nyc311.short[,3:ncol(nyc311.short)])
d <- dist(as.matrix(nyc.short), method = "euclidean")
hc <- hclust(d, method="ward.D")
# draw dendogram with red borders around the X clusters
plot(hc, main = "Hierarchical Clustering Example", cex = 0.001)
rect.hclust(hc, k = 10, border="red")
#Label groups
groups <- cutree(hc, k=10) # cut tree into 5 clusters
#Set color palette
palette(colorRampPalette(c('#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a'))(10))
#Graph lat-lons with color coding by cluster
op <- par(mar = rep(0, 4))
plot(nyc311.short$lon, nyc311.short$lat, col = factor(groups), pch = 15, cex = 0.2,
frame.plot=FALSE, yaxt='n', ann=FALSE, xaxt='n')
legend(x="topleft", bty = "n", legend=levels(factor(groups)),
cex = 1,  x.intersp=0, xjust=0, yjust=0, text.col=seq_along(levels(factor(groups))))
par(op)
recap <- sumUp(nyc311.short[,3:ncol(nyc311.short)], groups, 5)
recap
recap <- sumUp(nyc311.short[,3:ncol(nyc311.short)], groups, 5, horizontal = TRUE)
recap
