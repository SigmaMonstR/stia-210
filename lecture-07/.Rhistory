#############
##LECTURE 7##
#############
#Set your working drive
setwd("/Users/jeff/Documents/Github/data-science/lecture-07")
#Libraries required
install.packages(c("rpart","rpart.plot", "devtools", "gridExtra", "randomForest" ))
devtools::install_github("sachsmc/plotROC")
#Load data
health <- read.csv("data/lecture7.csv")
str(health)
#Randomly subset data into train and test
set.seed(100)
rand <- runif(nrow(health))
rand <- rand > 0.5
#Create train test sets
train <- health[rand == T, ]
test <- health[rand == F, ]
##################
##DECISION TREES##
##################
#Load rpart libraries
library(rpart)
library(rpart.plot)
library(ggplot2)
library(gridExtra)
library(plotROC)
#TRAIN MODEL
#Fit decision tree under default assumptions -- cp = 0.01
fit <- rpart(coverage ~ age + wage + cit + mar + educ + race,
method = "class", data = train)
#Tools to review output
printcp(fit)
#Use rpart.plot
rpart.plot(fit, shadow.col="gray", nn=TRUE)
#cp = 0
fit.0 <- rpart(coverage ~ age + wage + cit + mar + educ + race,
method = "class", data = train, cp = 0)
#Examine printcp to find optimal cp value
#Find lowest xerror
printcp(fit.0)
#Refit with optimal
fit.opt <- rpart(coverage ~ age + wage + cit + mar + educ + race,
method = "class", data = train, cp = 1.0885e-03)
rpart.plot(fit.opt, shadow.col="gray", nn=TRUE)
#Determine which variable had the greatest influence
fit.opt$variable.importance
#CALCULATE TEST ACCURACY
#Predict values for train set
pred.opt.train <- predict(fit.opt, train, type='prob')[,2]
pred.0.train <- predict(fit.0, train, type='prob')[,2]
pred.default.train <- predict(fit, train, type='prob')[,2]
#Predict values for test set
pred.opt.test <- predict(fit.opt, test, type='prob')[,2]
pred.0.test <- predict(fit.0, test, type='prob')[,2]
pred.default.test <- predict(fit, test, type='prob')[,2]
#Set up ROC inputs
input.test <- rbind(data.frame(model = "optimal", d = test$coverage, m = pred.opt.test),
data.frame(model = "CP = 0", d = test$coverage,  m = pred.0.test),
data.frame(model = "default", d = test$coverage,  m = pred.default.test))
input.train <- rbind(data.frame(model = "optimal", d = train$coverage,  m = pred.opt.train),
data.frame(model = "CP = 0", d = train$coverage,  m = pred.0.train),
data.frame(model = "default", d =  train$coverage,  m = pred.default.train))
#Graph all three ROCs
roc.test <- ggplot(input.test, aes(d = d, model = model, m = m, colour = model)) +
geom_roc(show.legend = TRUE) + style_roc()  + ggtitle("Test")
roc.train <- ggplot(input.train, aes(d = d, model = model, m = m, colour = model)) +
geom_roc(show.legend = TRUE) + style_roc()  +ggtitle("Train")
#Plot
grid.arrange(roc.train, roc.test, ncol = 2)
calc_auc(roc.test)
##################
##RANDOM FORESTS##
##################
#Load randomForest library
library(randomForest)
#############
##LECTURE 7##
#############
#Set your working drive
setwd("/Users/jeff/Documents/Github/data-science/lecture-07")
#Libraries required
install.packages(c("rpart","rpart.plot", "devtools", "gridExtra", "randomForest" ))
devtools::install_github("sachsmc/plotROC")
#Load data
health <- read.csv("data/lecture7.csv")
str(health)
#Randomly subset data into train and test
set.seed(100)
rand <- runif(nrow(health))
rand <- rand > 0.5
#Create train test sets
train <- health[rand == T, ]
test <- health[rand == F, ]
##################
##DECISION TREES##
##################
#Load rpart libraries
library(rpart)
library(rpart.plot)
library(ggplot2)
library(gridExtra)
library(plotROC)
#TRAIN MODEL
#Fit decision tree under default assumptions -- cp = 0.01
fit <- rpart(coverage ~ age + wage + cit + mar + educ + race,
method = "class", data = train)
#Tools to review output
printcp(fit)
#Use rpart.plot
rpart.plot(fit, shadow.col="gray", nn=TRUE)
#cp = 0
fit.0 <- rpart(coverage ~ age + wage + cit + mar + educ + race,
method = "class", data = train, cp = 0)
#Examine printcp to find optimal cp value
#Find lowest xerror
printcp(fit.0)
#Refit with optimal
fit.opt <- rpart(coverage ~ age + wage + cit + mar + educ + race,
method = "class", data = train, cp = 1.0885e-03)
rpart.plot(fit.opt, shadow.col="gray", nn=TRUE)
#Determine which variable had the greatest influence
fit.opt$variable.importance
#CALCULATE TEST ACCURACY
#Predict values for train set
pred.opt.train <- predict(fit.opt, train, type='prob')[,2]
pred.0.train <- predict(fit.0, train, type='prob')[,2]
pred.default.train <- predict(fit, train, type='prob')[,2]
#Predict values for test set
pred.opt.test <- predict(fit.opt, test, type='prob')[,2]
pred.0.test <- predict(fit.0, test, type='prob')[,2]
pred.default.test <- predict(fit, test, type='prob')[,2]
#Set up ROC inputs
input.test <- rbind(data.frame(model = "optimal", d = test$coverage, m = pred.opt.test),
data.frame(model = "CP = 0", d = test$coverage,  m = pred.0.test),
data.frame(model = "default", d = test$coverage,  m = pred.default.test))
input.train <- rbind(data.frame(model = "optimal", d = train$coverage,  m = pred.opt.train),
data.frame(model = "CP = 0", d = train$coverage,  m = pred.0.train),
data.frame(model = "default", d =  train$coverage,  m = pred.default.train))
#Graph all three ROCs
roc.test <- ggplot(input.test, aes(d = d, model = model, m = m, colour = model)) +
geom_roc(show.legend = TRUE) + style_roc()  + ggtitle("Test")
roc.train <- ggplot(input.train, aes(d = d, model = model, m = m, colour = model)) +
geom_roc(show.legend = TRUE) + style_roc()  +ggtitle("Train")
#Plot
grid.arrange(roc.train, roc.test, ncol = 2)
calc_auc(roc.test)
##################
##RANDOM FORESTS##
##################
#Load randomForest library
library(randomForest)
install.packages(c("rpart", "rpart.plot", "devtools", "gridExtra", "randomForest"))
#Load randomForest library
library(randomForest)
coverage[1:100] <- "asd"
train$coverage[1:100] <- "asd"
train$coverage
train$coverage[1:100] <- "asd"
train$coverage[1:100]
train$coverage <- as.character(train$coverage)
train$coverage[1:100] <- "asd"
#Run Random Forest
fit.rf <- randomForest(coverage ~ age + wage + cit + mar + educ + race, data = train)
#Run Random Forest
fit.rf <- randomForest(factor(coverage) ~ age + wage + cit + mar + educ + race, data = train)
#Predict values for train set
pred.rf.train <- predict(fit.rf, train, type='class')
pred.rf.train
table(pred.rf.train)
install.packages("e1071")
171000+65000+7000
meanf1 <- function(actual, predicted){
# Desc:
#   Weighted mean F1 score function
#
# Args:
#   actual = a vector of actual labels
#   predicted = predicted labels
#
# Returns:
#   Single value F1 score
#
classes <- unique(actual)
results <- data.frame()
#Loop through all classes
for(k in classes){
prec <- sum(predicted == k & actual == k)/sum(predicted == k)
rec <- sum(predicted == k & actual == k)/sum(actual == k)
results <- rbind(results,
data.frame(class.name = k,
weight = sum(actual == k)/length(actual),
precision = prec,
recall = rec))
}
#Calculate weighted mean
score <- results[,2] * 2 * (results[,3] * results[,4]) / (results[,3] + results[,4])
return(sum(results$score))
}
meanf1(c("a", "b", "c"), c("a", "a", "c"))
classes <- unique(actual)
results <- data.frame()
classes <- c("a", "b", "c")
results <- data.frame()
for(k in classes){
prec <- sum(predicted == k & actual == k)/sum(predicted == k)
rec <- sum(predicted == k & actual == k)/sum(actual == k)
results <- rbind(results,
data.frame(class.name = k,
weight = sum(actual == k)/length(actual),
precision = prec,
recall = rec))
}
predicted <- c("a", "b", "c")
actual <- predicted
for(k in classes){
prec <- sum(predicted == k & actual == k)/sum(predicted == k)
rec <- sum(predicted == k & actual == k)/sum(actual == k)
results <- rbind(results,
data.frame(class.name = k,
weight = sum(actual == k)/length(actual),
precision = prec,
recall = rec))
}
results
#Calculate weighted mean
score <- results[,2] * 2 * (results[,3] * results[,4]) / (results[,3] + results[,4])
scores
return(sum(score))
sum(score)
meanf1 <- function(actual, predicted){
# Desc:
#   Weighted mean F1 score function
#
# Args:
#   actual = a vector of actual labels
#   predicted = predicted labels
#
# Returns:
#   Single value F1 score
#
classes <- unique(actual)
results <- data.frame()
#Loop through all classes
for(k in classes){
prec <- sum(predicted == k & actual == k)/sum(predicted == k)
rec <- sum(predicted == k & actual == k)/sum(actual == k)
results <- rbind(results,
data.frame(class.name = k,
weight = sum(actual == k)/length(actual),
precision = prec,
recall = rec))
}
#Calculate weighted mean
score <- results[,2] * 2 * (results[,3] * results[,4]) / (results[,3] + results[,4])
return(sum(score))
}
meanf1(c("a", "b", "c"), c("a", "a", "c"))
meanf1 <- function(actual, predicted){
# Desc:
#   Weighted mean F1 score function
#
# Args:
#   actual = a vector of actual labels
#   predicted = predicted labels
#
# Returns:
#   Single value F1 score
#
classes <- unique(actual)
results <- data.frame()
#Loop through all classes
for(k in classes){
prec <- sum(predicted == k & actual == k)/sum(predicted == k)
rec <- sum(predicted == k & actual == k)/sum(actual == k)
results <- rbind(results,
data.frame(class.name = k,
weight = sum(actual == k)/length(actual),
precision = prec,
recall = rec))
}
#Calculate weighted mean
score <- results[,2] * 2 * (results[,3] * results[,4]) / (results[,3] + results[,4])
return(sum(score, na.rm = TRUE))
}
meanf1(c("a", "b", "c"), c("a", "a", "c"))
library(rio)
import("https://raw.githubusercontent.com/GeorgetownMcCourt/data-science/master/homework_data/accel.Rda")
tempfile <- tempfile()
download.file("https://raw.githubusercontent.com/GeorgetownMcCourt/data-science/master/homework_data/accel.Rda", temp)
temp <- tempfile()
download.file("https://raw.githubusercontent.com/GeorgetownMcCourt/data-science/master/homework_data/accel.Rda", temp)
load(tempfile)
load(temp)
